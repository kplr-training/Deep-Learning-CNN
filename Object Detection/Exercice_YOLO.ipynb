{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "view-in-github",
                "colab_type": "text"
            },
            "source": [
                "<a href=\"https://colab.research.google.com/github/kplr-training/Deep-Learning-CNN/blob/main/Object%20Detection/Exercice_YOLO.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **Reconnaissance des plaques d'immatriculation \u00e0 l'aide de YoLo et DarkNet**"
            ],
            "metadata": {
                "id": "9opVMK6RKrHO"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "<img src='https://betterdatascience.com/detect-license-plates-with-yolo/images/1.jpg'>\n",
                "\n"
            ],
            "metadata": {
                "id": "cc0nQblznWeL"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **Darknet :**"
            ],
            "metadata": {
                "id": "5e-2KC_QofpI"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "<img src='https://miro.medium.com/v2/resize:fit:512/0*GFsAY18k3A25IpRL'>"
            ],
            "metadata": {
                "id": "CmPifM2wot2N"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "- Darknet est un framework de r\u00e9seau de neurones d\u00e9velopp\u00e9 par Joseph Chet Redom. \n",
                "- Il s'agit essentiellement de nous fournir \u00e0 tous un terrain de jeu pour construire nos propres mod\u00e8les de r\u00e9seaux de neurones. \n",
                "- Ce framework est \u00e9crit en \u00ab C \u00bb et \u00ab CUDA \u00bb. \n",
                "- Il est rapide et prend en charge les calculs CPU et GPU. \n",
                "-  Ce framework d\u00e9pend des packages OpenCV et CUDA. Il prend en charge une large gamme de mod\u00e8les tels que YOLO, RNN, etc. \n",
                "- Pour plus d'informations sur Darknet, vous pouvez visiter ce site Web https://pjreddie.com/darknet/ ."
            ],
            "metadata": {
                "id": "S1-DhzNIpR-7"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **YOLO _ V3 :**"
            ],
            "metadata": {
                "id": "0djjVef2pgGE"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "- YOLO signifie Y ou O nly L ook O nce. C'est l'un des algorithmes avanc\u00e9s actuels lorsque vous avez besoin d'une d\u00e9tection en temps r\u00e9el (en millisecondes) de la classe et de la pr\u00e9diction de la classe de cet objet d\u00e9tect\u00e9. \n",
                "- D'autre part, ce n'est pas l'algorithme le plus pr\u00e9cis, mais c'est le meilleur des mod\u00e8les de d\u00e9tection pr\u00e9cis en temps r\u00e9el.\n",
                "- Avant la version, nous avions les mod\u00e8les yolo_v1 et yolo_v2. vous pouvez obtenir plus de d\u00e9tails dans leurs documents officiels publi\u00e9s. yolo_v1 et yolo_v2 .\n",
                "\n",
                "- J'essaie d'expliquer un peu l'architecture v3. Il a un total de 106 couches. - Le meilleur avantage de ce mod\u00e8le est qu'il fait des pr\u00e9dictions \u00e0 trois \u00e9chelles ( \u00e0 la couche - 82 , 94 , 106 ). \n",
                "- Et en m\u00eame temps, les images seront sous-\u00e9chantillonn\u00e9es leurs dimensions \u00e0 52 X 52 , 26X26 , 13X13 respectivement dans ces couches. Peu d'avantages sont\n",
                "\n",
                "1 . \n",
                "- Les caract\u00e9ristiques sont d\u00e9tect\u00e9es en multi-\u00e9chelle (52 x 52 , 26 x 26 , 13x13 ).\n",
                "\n",
                "2. R\u00e9seau d'extracteurs de fonctionnalit\u00e9s plus puissant\n",
                "\n",
                "3. Fonction de perte optimis\u00e9e\n",
                "\n",
                "- L'image suivante vous donne un aper\u00e7u plus d\u00e9taill\u00e9 de toutes les couches.\n",
                "\n"
            ],
            "metadata": {
                "id": "kYnbIS3Vpi-k"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "<img src='https://miro.medium.com/v2/resize:fit:1100/format:webp/0*3v10JDBF-1CApcQV.png'>"
            ],
            "metadata": {
                "id": "jBQ4DtKmpy3G"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "- \u00c0 haut niveau, les couches ci-dessus peuvent \u00eatre divis\u00e9es en deux cat\u00e9gories principales - Feature Extractor et Detector. \n",
                "- Lorsqu'une nouvelle image arrive dans le r\u00e9seau, elle passe d'abord par l'extracteur de caract\u00e9ristiques (les caract\u00e9ristiques sortiront \u00e0 trois \u00e9tapes diff\u00e9rentes \u00e0 trois \u00e9chelles diff\u00e9rentes), puis ces caract\u00e9ristiques sont introduites dans la branche du d\u00e9tecteur pour d\u00e9tecter les bo\u00eetes englobantes autour des objets d\u00e9tect\u00e9s et enfin ces bo\u00eetes englobantes seront class\u00e9es dans l'une des cat\u00e9gories."
            ],
            "metadata": {
                "id": "A1tZ3TpBqAVF"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "<img src='https://miro.medium.com/v2/resize:fit:1100/format:webp/0*RTdjlhEkAsFBMsU4.jpeg'>"
            ],
            "metadata": {
                "id": "2BM_4tj2qJoK"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **Extracteur de fonctionnalit\u00e9s :**"
            ],
            "metadata": {
                "id": "GbA9wmwoqdV0"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "- La fonctionnalit\u00e9 extracor dans YOLO V3 (\u00e9galement appel\u00e9e Darknet -53) comporte elle-m\u00eame 53 couches distinctes (sur un total de 106 couches). \n",
                "- Ces 53 couches de Darknet peuvent \u00eatre expliqu\u00e9es avec le tableau suivant.\n",
                "<img src='https://miro.medium.com/v2/resize:fit:640/format:webp/0*lKqQiOgaDBjpjcZo.jpeg'>"
            ],
            "metadata": {
                "id": "275WqQuCqfTw"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "- L'ensemble total du cadre peut \u00eatre divis\u00e9 en petits blocs ind\u00e9pendants qui sont connect\u00e9s avec une couche de 2 convolutions. \n",
                "- Nous pouvons directement convertir cet extracteur de caract\u00e9ristiques en classificateur en ajoutant trois couches distinctes (Avg-pool Connected et Soft-max). \n",
                "- Mais dans notre application de d\u00e9tection d'objets, nous utilisons ce Darknet-53 comme seul extracteur de fonctionnalit\u00e9s et est connect\u00e9 \u00e0 un bloc de couches de d\u00e9tection. \n",
                "- Nous n'inclurons donc pas les trois derni\u00e8res couches dans notre mod\u00e8le.\n",
                "\n",
                "- \u00c0 partir de cet extracteur de caract\u00e9ristiques, si nous ins\u00e9rons une image, cela donnera trois vecteurs de caract\u00e9ristiques \u00e0 diff\u00e9rentes \u00e9tapes du flux de r\u00e9seau. \n",
                "- Ces trois fonctionnalit\u00e9s seront ins\u00e9r\u00e9es s\u00e9par\u00e9ment dans le bloc D\u00e9tecteur."
            ],
            "metadata": {
                "id": "QqMVK-ApquqQ"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Importer la data depuis Kaggle**"
            ],
            "metadata": {
                "id": "T9QWeQ_-NIJI"
            }
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "WK8TRn_E6iy4"
            },
            "outputs": [],
            "source": [
                "!pip install -q kaggle"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "!mkdir ~/.kaggle"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "9AqUby-W8Spj",
                "outputId": "ce95a2e4-b54c-49df-e4ff-aae2d56a37d7"
            },
            "execution_count": null,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "mkdir: cannot create directory \u2018/root/.kaggle\u2019: File exists\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "!cp kaggle.json ~/.kaggle/"
            ],
            "metadata": {
                "id": "njeIZLvm8Vch"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "!chmod 600 ~/.kaggle/kaggle.json"
            ],
            "metadata": {
                "id": "er_lJoOa8a6B"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "!kaggle datasets download -d elysian01/car-number-plate-detection"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "NLOipWVw8g3z",
                "outputId": "cc99bbcd-fe1c-4d59-ca77-5bd5dfec5a99"
            },
            "execution_count": null,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Downloading car-number-plate-detection.zip to /content\n",
                        "100% 2.69G/2.69G [01:40<00:00, 33.2MB/s]\n",
                        "100% 2.69G/2.69G [01:40<00:00, 28.8MB/s]\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "!kaggle datasets download -d achrafkhazri/yolo-weights-for-licence-plate-detector"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "7AdqnKpK9qHr",
                "outputId": "2ed1a3de-79e7-487e-ed32-bf7952ebf88d"
            },
            "execution_count": null,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Downloading yolo-weights-for-licence-plate-detector.zip to /content\n",
                        " 99% 216M/218M [00:08<00:00, 24.3MB/s]\n",
                        "100% 218M/218M [00:08<00:00, 25.6MB/s]\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Importer les Biblioth\u00e8ques**"
            ],
            "metadata": {
                "id": "lLimpIbUNQdq"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import os\n",
                "import cv2\n",
                "import time\n",
                "import random\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.utils import to_categorical\n",
                "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
                "import zipfile"
            ],
            "metadata": {
                "id": "Drqi3G-T9xQs"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Extraction des fichiers ZIP**"
            ],
            "metadata": {
                "id": "HJcfQr1rNWFa"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Sp\u00e9cifiez le chemin du fichier ZIP\n",
                "zip_file_path = '/content/car-number-plate-detection.zip'\n",
                "# Sp\u00e9cifiez le r\u00e9pertoire o\u00f9 vous souhaitez extraire les fichiers\n",
                "extract_directory = '/content/car-number-plate-detection'\n",
                "# Ouvrez le fichier ZIP\n",
                "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
                "    # Extrayez tous les contenus du fichier ZIP dans le r\u00e9pertoire sp\u00e9cifi\u00e9\n",
                "    zip_ref.extractall(extract_directory)\n",
                "print(\"Extraction termin\u00e9e.\")"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "tMfS3NgT-GgR",
                "outputId": "d6bb4b11-8b23-42f0-f3c6-265344b902b3"
            },
            "execution_count": null,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Unzipping complete.\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "# Sp\u00e9cifiez le chemin du fichier ZIP\n",
                "zip_file_path = '/content/yolo-weights-for-licence-plate-detector.zip'\n",
                "# Sp\u00e9cifiez le r\u00e9pertoire o\u00f9 vous souhaitez extraire les fichiers\n",
                "extract_directory = '/content/yolo-weights-for-licence-plate-detector'\n",
                "# Ouvrez le fichier ZIP\n",
                "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
                "    # Extrayez tous les contenus du fichier ZIP dans le r\u00e9pertoire sp\u00e9cifi\u00e9\n",
                "    zip_ref.extractall(extract_directory)\n",
                "print(\"Unzipping complete.\")"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "N3TaUQca-TCQ",
                "outputId": "6cceb07c-437f-4160-ead7-eddfec0a97d7"
            },
            "execution_count": null,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Unzipping complete.\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Parcours r\u00e9cursif d'un r\u00e9pertoire et r\u00e9cup\u00e9ration des chemins de fichiers**"
            ],
            "metadata": {
                "id": "O9DhovnmNx6_"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import os\n",
                "\n",
                "# Liste pour stocker les chemins des fichiers\n",
                "paths = []\n",
                "\n",
                "# Parcourir r\u00e9cursivement le r\u00e9pertoire '/content/car-number-plate-detection/Car_Number_Plate'\n",
                "# et r\u00e9cup\u00e9rer les chemins de tous les fichiers\n",
                "for dirname, _, filenames in os.walk('/content/car-number-plate-detection/Car_Number_Plate'):\n",
                "    for filename in filenames:\n",
                "        # Ajouter le chemin complet du fichier \u00e0 la liste des chemins\n",
                "        paths.append(os.path.join(dirname, filename))"
            ],
            "metadata": {
                "id": "PVaNjgCy9ygU"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "n=len(paths)\n",
                "N=6"
            ],
            "metadata": {
                "id": "RDwi9jAj_LiE"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "labels = open('/content/yolo-weights-for-licence-plate-detector/classes.names').read()"
            ],
            "metadata": {
                "id": "WIrJHlKI_N14"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Chemin vers les poids du mod\u00e8le YOLO\n",
                "weights_path = '/content/yolo-weights-for-licence-plate-detector/lapi.weights'\n",
                "# Chemin vers la configuration du mod\u00e8le YOLO\n",
                "configuration_path = '/content/yolo-weights-for-licence-plate-detector/darknet-yolov3.cfg'\n",
                "# Probabilit\u00e9 minimum pour filtrer les d\u00e9tections\n",
                "probability_minimum = 0.4\n",
                "# Seuil pour la suppression des d\u00e9tections faibles\n",
                "threshold = 0.3"
            ],
            "metadata": {
                "id": "Y4cxJMbQ_W5v"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Configuration du mod\u00e8le YOLO et param\u00e8tres de d\u00e9tection**"
            ],
            "metadata": {
                "id": "zmDFpslWN-e-"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Charger le mod\u00e8le Darknet \u00e0 partir de la configuration et des poids\n",
                "network = cv2.dnn.readNetFromDarknet(configuration_path, weights_path)\n",
                "\n",
                "# R\u00e9cup\u00e9rer les noms de toutes les couches du r\u00e9seau\n",
                "layers_names_all = network.getLayerNames()\n",
                "\n",
                "# R\u00e9cup\u00e9rer les indices des couches de sortie non connect\u00e9es\n",
                "layers_indices_output = network.getUnconnectedOutLayers()\n",
                "\n",
                "# V\u00e9rifier si layers_indices_output est un entier\n",
                "if isinstance(layers_indices_output, int):\n",
                "    # Convertir en liste\n",
                "    layers_indices_output = [layers_indices_output]\n",
                "\n",
                "# R\u00e9cup\u00e9rer les noms des couches de sortie \u00e0 partir des indices\n",
                "layers_names_output = [layers_names_all[i - 1] for i in layers_indices_output]"
            ],
            "metadata": {
                "id": "O5pWT0gY_ity"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Chargement et affichage de l'image**"
            ],
            "metadata": {
                "id": "jx5gC8Z4OZn2"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Lire l'image \u00e0 partir du chemin sp\u00e9cifi\u00e9\n",
                "image_input = cv2.imread(paths[N])\n",
                "\n",
                "# Redimensionner l'image en utilisant un facteur de r\u00e9duction de 0.2\n",
                "image_input = cv2.resize(image_input, dsize=None, fx=0.2, fy=0.2)\n",
                "\n",
                "# Afficher l'image en utilisant Matplotlib\n",
                "%matplotlib inline\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Configurer la taille de la figure\n",
                "plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
                "\n",
                "# Afficher l'image convertie en espace de couleur RGB\n",
                "plt.imshow(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))\n",
                "plt.show()\n"
            ],
            "metadata": {
                "id": "C159F9yS_8Fq"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Pr\u00e9paration de l'image pour la d\u00e9tection avec YOLO**"
            ],
            "metadata": {
                "id": "cYL_WuYTQrKR"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Exercice : Convertir une image en blob d'entr\u00e9e pour le r\u00e9seau YOLO**\n",
                "\n",
                "- Dans cet exercice, nous allons convertir une image en un blob d'entr\u00e9e pour le r\u00e9seau YOLO en utilisant OpenCV. \n",
                "- Le blob d'entr\u00e9e est une repr\u00e9sentation pr\u00e9trait\u00e9e de l'image qui peut \u00eatre utilis\u00e9e pour effectuer des pr\u00e9dictions d'objets avec le r\u00e9seau YOLO.\n",
                "\n",
                "- Voici le code \u00e0 compl\u00e9ter :"
            ],
            "metadata": {
                "id": "QkYSRjO2swd0"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import cv2\n",
                "import numpy as np\n",
                "# Lire l'image \u00e0 partir du chemin sp\u00e9cifi\u00e9\n",
                "image_input = cv2.imread(\"chemin/vers/l/image.jpg\")\n",
                "# Convertir l'image en un blob d'entr\u00e9e pour le r\u00e9seau YOLO\n",
                "blob = cv2.dnn.blobFromImage(#fill_here, #fill_here, #fill_here, #fill_here, #fill_here)\n",
                "# R\u00e9organiser les dimensions du blob pour l'affichage\n",
                "blob_to_show = blob[0,:,:,:].transpose(#fill_here)\n",
                "# D\u00e9finir le blob en tant qu'entr\u00e9e pour le r\u00e9seau\n",
                "network.setInput(#fill_here)\n",
                "# Obtenir les sorties du r\u00e9seau pour les couches de sortie sp\u00e9cifi\u00e9es\n",
                "output_from_network = network.forward(#fill_here)\n",
                "# G\u00e9n\u00e9rer des couleurs al\u00e9atoires pour chaque \u00e9tiquette de classe\n",
                "np.random.seed(42)\n",
                "colours = np.random.randint(#fill_here, #fill_here, size=(#fill_here, #fill_here), dtype='uint8')\n"
            ],
            "metadata": {
                "id": "oaPV9A5AAAMv"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Instructions :**\n",
                "1.  Utilisez la m\u00e9thode cv2.dnn.blobFromImage() pour convertir l'image en un blob d'entr\u00e9e pour le r\u00e9seau YOLO. Utilisez les arguments appropri\u00e9s pour effectuer la conversion. Le facteur d'\u00e9chelle (scalefactor) est 1/255.0, la taille du blob (size) est (416, 416), swapRB est True et crop est False. Assignez le r\u00e9sultat \u00e0 la variable blob.\n",
                "2.  R\u00e9organisez les dimensions du blob pour l'affichage en utilisant la m\u00e9thode transpose() de l'objet blob. Les axes \u00e0 transposer sont 0, 1 et 2, dans cet ordre. Assignez le r\u00e9sultat \u00e0 la variable blob_to_show.\n",
                "3.  D\u00e9finissez le blob en tant qu'entr\u00e9e pour le r\u00e9seau en utilisant la m\u00e9thode setInput() de l'objet network. Passez le blob en tant qu'argument.\n",
                "4.  Obtenez les sorties du r\u00e9seau pour les couches de sortie sp\u00e9cifi\u00e9es en utilisant la m\u00e9thode forward() de l'objet network. Passez les noms des couches de sortie (layers_names_output) en tant qu'argument. Assignez le r\u00e9sultat \u00e0 la variable output_from_network.\n",
                "5.  G\u00e9n\u00e9rez des couleurs al\u00e9atoires pour chaque \u00e9tiquette de classe en utilisant la m\u00e9thode random.randint() de l'objet np. Les arguments pour randint() sont la valeur minimale (low), la valeur maximale (high), la taille (size) de la matrice de couleurs et le type de donn\u00e9es (dtype) en tant que 'uint8'. Utilisez np.random.seed(42) pour fixer la graine al\u00e9atoire. "
            ],
            "metadata": {
                "id": "tlFfr5cTuAWo"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **D\u00e9tection d'objets avec YOLO et r\u00e9cup\u00e9ration des r\u00e9sultats**"
            ],
            "metadata": {
                "id": "aVJsT55uQ53S"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Exercice : Traitement des r\u00e9sultats de d\u00e9tection avec YOLO**\n",
                "\n",
                "- Dans cet exercice, nous allons traiter les r\u00e9sultats de d\u00e9tection obtenus \u00e0 partir du r\u00e9seau YOLO. \n",
                "- Nous allons extraire les bo\u00eetes englobantes, les confiances et les num\u00e9ros de classe associ\u00e9s \u00e0 chaque d\u00e9tection."
            ],
            "metadata": {
                "id": "q--Q-F5uwzKk"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import numpy as np\n",
                "\n",
                "# Listes pour stocker les bo\u00eetes englobantes, les confiances et les num\u00e9ros de classe\n",
                "bounding_boxes = []\n",
                "confidences = []\n",
                "class_numbers = []\n",
                "\n",
                "# R\u00e9cup\u00e9rer les dimensions de l'image\n",
                "h, w = image_input.shape[:2]\n",
                "\n",
                "# Parcourir les r\u00e9sultats de la sortie du r\u00e9seau\n",
                "for result in output_from_network:\n",
                "    # Parcourir les d\u00e9tections dans chaque r\u00e9sultat\n",
                "    for detection in result:\n",
                "        # R\u00e9cup\u00e9rer les scores de confiance pour chaque classe\n",
                "        scores = detection[#fill_here_:]\n",
                "\n",
                "        # Trouver l'indice de classe avec la plus haute probabilit\u00e9\n",
                "        class_current =#fill_here\n",
                "\n",
                "        # R\u00e9cup\u00e9rer la confiance pour la classe actuelle\n",
                "        confidence_current = score[class_current]\n",
                "\n",
                "        # V\u00e9rifier si la confiance d\u00e9passe le seuil minimum\n",
                "        if #fill_here:\n",
                "            # R\u00e9cup\u00e9rer les coordonn\u00e9es de la bo\u00eete englobante et les ajuster \u00e0 la taille de l'image originale\n",
                "            box_current = detection[#fill_here:#fill_here] * np.array([w, h, w, h])\n",
                "            x_center, y_center, box_width, box_height = box_current.astype('int')\n",
                "            x_min = int(#fill_here)\n",
                "            y_min = int(#fill_here)\n",
                "\n",
                "            # Ajouter la bo\u00eete englobante, la confiance et le num\u00e9ro de classe aux listes correspondantes\n",
                "            bounding_boxes.append([#fill_here, #fill_here, int(#fill_here), int(#fill_here)])\n",
                "            confidences.append(float(confidence_current))\n",
                "            class_numbers.append(class_current)\n"
            ],
            "metadata": {
                "id": "Ka7mcusEAEEI"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Instructions :**\n",
                "\n",
                "- Cr\u00e9ez les listes bounding_boxes, confidences et class_numbers pour stocker respectivement les bo\u00eetes englobantes, les confiances et les num\u00e9ros de classe associ\u00e9s \u00e0 chaque d\u00e9tection.\n",
                "- R\u00e9cup\u00e9rez les dimensions de l'image en utilisant la m\u00e9thode shape de l'objet image_input et assignez les valeurs aux variables h et w.\n",
                "- Parcourez les r\u00e9sultats de la sortie du r\u00e9seau en utilisant une boucle for avec la variable result.\n",
                "- \u00c0 l'int\u00e9rieur de la boucle, parcourez les d\u00e9tections dans chaque r\u00e9sultat en utilisant une boucle for avec la variable detection.\n",
                "- R\u00e9cup\u00e9rez les scores de confiance pour chaque classe en utilisant la notation de d\u00e9coupage ([5:]) sur la variable detection. Assignez les valeurs \u00e0 la variable scores.\n",
                "- Trouvez l'indice de classe avec la plus haute probabilit\u00e9 en utilisant np.argmax(scores). Assignez la valeur \u00e0 la variable class_current.\n",
                "- R\u00e9cup\u00e9rez la confiance pour la classe actuelle en utilisant l'indice class_current dans la variable scores. Assignez la valeur \u00e0 la variable confidence_current.\n",
                "- Compl\u00e9tez la condition if pour v\u00e9rifier si la confidence_current est sup\u00e9rieure au seuil minimum probability_minimum.\n",
                "- \u00c0 l'int\u00e9rieur de la condition, r\u00e9cup\u00e9rez les coordonn\u00e9es de la bo\u00eete englobante en utilisant la notation de d\u00e9coupage ([0:4]) sur la variable detection. Multipliez ensuite les coordonn\u00e9es par un tableau de facteurs pour ajuster les coordonn\u00e9es \u00e0 la taille de l'image originale. Assignez les valeurs respectivement aux variables x_center, y_center, box_width et box_height.\n",
                "- Calculez les valeurs x_min et y_min en utilisant les variables x_center, y_center, box_width et box_height.\n",
                "- Ajoutez la bo\u00eete englobante \u00e0 la liste bounding_boxes en utilisant la m\u00e9thode append avec une liste contenant x_min, y_min, int(box_width) et int(box_height).\n",
                "- Ajoutez la confiance \u00e0 la liste confidences en utilisant la m\u00e9thode append avec la valeur float(confidence_current).\n",
                "- Ajoutez le num\u00e9ro de classe \u00e0 la liste class_numbers en utilisant la m\u00e9thode append avec la valeur class_current."
            ],
            "metadata": {
                "id": "iLixVgiVw_XV"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Suppression des d\u00e9tections redondantes avec la suppression non maximale (NMS)**"
            ],
            "metadata": {
                "id": "WfTON2gLeYiI"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Supprimer les d\u00e9tections redondantes \u00e0 l'aide de la suppression non maximale (NMS)\n",
                "results = cv2.dnn.NMSBoxes(bounding_boxes, confidences, probability_minimum, threshold)\n",
                "\n",
                "# V\u00e9rifier s'il y a des r\u00e9sultats apr\u00e8s la suppression non maximale\n",
                "if len(results) > 0\n",
                "    # Parcourir les r\u00e9sultats aplatis\n",
                "    for i in results.flatten():\n",
                "        # R\u00e9cup\u00e9rer les coordonn\u00e9es et les dimensions de la bo\u00eete englobante\n",
                "        x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
                "        box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
                "        \n",
                "        # R\u00e9cup\u00e9rer la couleur de la bo\u00eete englobante pour la classe actuelle\n",
                "        colour_box_current = [int(j) for j in colours[class_numbers[i]]]\n",
                "        \n",
                "        # Dessiner la bo\u00eete englobante sur l'image d'entr\u00e9e\n",
                "        cv2.rectangle(image_input, (x_min, y_min), (x_min + box_width, y_min + box_height),\n",
                "                      colour_box_current, 5)\n",
                "        \n",
                "        # Ajouter le texte de la classe et de la confiance sur l'image d'entr\u00e9e\n",
                "        text_box_current = '{}: {:.4f}'.format(labels[int(class_numbers[i])], confidences[i])\n",
                "        cv2.putText(image_input, text_box_current, (x_min, y_min - 7), cv2.FONT_HERSHEY_SIMPLEX,\n",
                "                    1.5, colour_box_current, 5)\n"
            ],
            "metadata": {
                "id": "ZdlY_PJnAG2i"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "import matplotlib.pyplot as plt\n",
                "# Configurer la taille de la figure\n",
                "plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
                "# Afficher l'image convertie en espace de couleur RGB\n",
                "plt.imshow(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))\n",
                "plt.show()\n"
            ],
            "metadata": {
                "id": "Umv3UBjmAJHD"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}