{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "view-in-github",
                "colab_type": "text"
            },
            "source": [
                "<a href=\"https://colab.research.google.com/github/kplr-training/Deep-Learning-CNN/blob/main/Object%20Detection/Solution_YOLO.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **Reconnaissance des plaques d'immatriculation \u00e0 l'aide de YoLo et DarkNet**"
            ],
            "metadata": {
                "id": "9opVMK6RKrHO"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "<img src='https://betterdatascience.com/detect-license-plates-with-yolo/images/1.jpg'>\n",
                "\n"
            ],
            "metadata": {
                "id": "cc0nQblznWeL"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **Darknet :**"
            ],
            "metadata": {
                "id": "5e-2KC_QofpI"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "<img src='https://miro.medium.com/v2/resize:fit:512/0*GFsAY18k3A25IpRL'>"
            ],
            "metadata": {
                "id": "CmPifM2wot2N"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "- Darknet est un framework de r\u00e9seau de neurones d\u00e9velopp\u00e9 par Joseph Chet Redom. \n",
                "- Il s'agit essentiellement de nous fournir \u00e0 tous un terrain de jeu pour construire nos propres mod\u00e8les de r\u00e9seaux de neurones. \n",
                "- Ce framework est \u00e9crit en \u00ab C \u00bb et \u00ab CUDA \u00bb. \n",
                "- Il est rapide et prend en charge les calculs CPU et GPU. \n",
                "-  Ce framework d\u00e9pend des packages OpenCV et CUDA. Il prend en charge une large gamme de mod\u00e8les tels que YOLO, RNN, etc. \n",
                "- Pour plus d'informations sur Darknet, vous pouvez visiter ce site Web https://pjreddie.com/darknet/ ."
            ],
            "metadata": {
                "id": "S1-DhzNIpR-7"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **YOLO _ V3 :**"
            ],
            "metadata": {
                "id": "0djjVef2pgGE"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "- YOLO signifie Y ou O nly L ook O nce. C'est l'un des algorithmes avanc\u00e9s actuels lorsque vous avez besoin d'une d\u00e9tection en temps r\u00e9el (en millisecondes) de la classe et de la pr\u00e9diction de la classe de cet objet d\u00e9tect\u00e9. \n",
                "- D'autre part, ce n'est pas l'algorithme le plus pr\u00e9cis, mais c'est le meilleur des mod\u00e8les de d\u00e9tection pr\u00e9cis en temps r\u00e9el.\n",
                "- Avant la version, nous avions les mod\u00e8les yolo_v1 et yolo_v2. vous pouvez obtenir plus de d\u00e9tails dans leurs documents officiels publi\u00e9s. yolo_v1 et yolo_v2 .\n",
                "\n",
                "- J'essaie d'expliquer un peu l'architecture v3. Il a un total de 106 couches. - Le meilleur avantage de ce mod\u00e8le est qu'il fait des pr\u00e9dictions \u00e0 trois \u00e9chelles ( \u00e0 la couche - 82 , 94 , 106 ). \n",
                "- Et en m\u00eame temps, les images seront sous-\u00e9chantillonn\u00e9es leurs dimensions \u00e0 52 X 52 , 26X26 , 13X13 respectivement dans ces couches. Peu d'avantages sont\n",
                "\n",
                "1 . \n",
                "- Les caract\u00e9ristiques sont d\u00e9tect\u00e9es en multi-\u00e9chelle (52 x 52 , 26 x 26 , 13x13 ).\n",
                "\n",
                "2. R\u00e9seau d'extracteurs de fonctionnalit\u00e9s plus puissant\n",
                "\n",
                "3. Fonction de perte optimis\u00e9e\n",
                "\n",
                "- L'image suivante vous donne un aper\u00e7u plus d\u00e9taill\u00e9 de toutes les couches.\n",
                "\n"
            ],
            "metadata": {
                "id": "kYnbIS3Vpi-k"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "<img src='https://miro.medium.com/v2/resize:fit:1100/format:webp/0*3v10JDBF-1CApcQV.png'>"
            ],
            "metadata": {
                "id": "jBQ4DtKmpy3G"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "- \u00c0 haut niveau, les couches ci-dessus peuvent \u00eatre divis\u00e9es en deux cat\u00e9gories principales - Feature Extractor et Detector. \n",
                "- Lorsqu'une nouvelle image arrive dans le r\u00e9seau, elle passe d'abord par l'extracteur de caract\u00e9ristiques (les caract\u00e9ristiques sortiront \u00e0 trois \u00e9tapes diff\u00e9rentes \u00e0 trois \u00e9chelles diff\u00e9rentes), puis ces caract\u00e9ristiques sont introduites dans la branche du d\u00e9tecteur pour d\u00e9tecter les bo\u00eetes englobantes autour des objets d\u00e9tect\u00e9s et enfin ces bo\u00eetes englobantes seront class\u00e9es dans l'une des cat\u00e9gories."
            ],
            "metadata": {
                "id": "A1tZ3TpBqAVF"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "<img src='https://miro.medium.com/v2/resize:fit:1100/format:webp/0*RTdjlhEkAsFBMsU4.jpeg'>"
            ],
            "metadata": {
                "id": "2BM_4tj2qJoK"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "# **Extracteur de fonctionnalit\u00e9s :**"
            ],
            "metadata": {
                "id": "GbA9wmwoqdV0"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "- La fonctionnalit\u00e9 extracor dans YOLO V3 (\u00e9galement appel\u00e9e Darknet -53) comporte elle-m\u00eame 53 couches distinctes (sur un total de 106 couches). \n",
                "- Ces 53 couches de Darknet peuvent \u00eatre expliqu\u00e9es avec le tableau suivant.\n",
                "<img src='https://miro.medium.com/v2/resize:fit:640/format:webp/0*lKqQiOgaDBjpjcZo.jpeg'>"
            ],
            "metadata": {
                "id": "275WqQuCqfTw"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "- L'ensemble total du cadre peut \u00eatre divis\u00e9 en petits blocs ind\u00e9pendants qui sont connect\u00e9s avec une couche de 2 convolutions. \n",
                "- Nous pouvons directement convertir cet extracteur de caract\u00e9ristiques en classificateur en ajoutant trois couches distinctes (Avg-pool Connected et Soft-max). \n",
                "- Mais dans notre application de d\u00e9tection d'objets, nous utilisons ce Darknet-53 comme seul extracteur de fonctionnalit\u00e9s et est connect\u00e9 \u00e0 un bloc de couches de d\u00e9tection. \n",
                "- Nous n'inclurons donc pas les trois derni\u00e8res couches dans notre mod\u00e8le.\n",
                "\n",
                "- \u00c0 partir de cet extracteur de caract\u00e9ristiques, si nous ins\u00e9rons une image, cela donnera trois vecteurs de caract\u00e9ristiques \u00e0 diff\u00e9rentes \u00e9tapes du flux de r\u00e9seau. \n",
                "- Ces trois fonctionnalit\u00e9s seront ins\u00e9r\u00e9es s\u00e9par\u00e9ment dans le bloc D\u00e9tecteur."
            ],
            "metadata": {
                "id": "QqMVK-ApquqQ"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Importer la data depuis Kaggle**"
            ],
            "metadata": {
                "id": "T9QWeQ_-NIJI"
            }
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "WK8TRn_E6iy4"
            },
            "outputs": [],
            "source": [
                "!pip install -q kaggle"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "!mkdir ~/.kaggle"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "9AqUby-W8Spj",
                "outputId": "ce95a2e4-b54c-49df-e4ff-aae2d56a37d7"
            },
            "execution_count": null,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "mkdir: cannot create directory \u2018/root/.kaggle\u2019: File exists\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "!cp kaggle.json ~/.kaggle/"
            ],
            "metadata": {
                "id": "njeIZLvm8Vch"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "!chmod 600 ~/.kaggle/kaggle.json"
            ],
            "metadata": {
                "id": "er_lJoOa8a6B"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "!kaggle datasets download -d elysian01/car-number-plate-detection"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "NLOipWVw8g3z",
                "outputId": "cc99bbcd-fe1c-4d59-ca77-5bd5dfec5a99"
            },
            "execution_count": null,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Downloading car-number-plate-detection.zip to /content\n",
                        "100% 2.69G/2.69G [01:40<00:00, 33.2MB/s]\n",
                        "100% 2.69G/2.69G [01:40<00:00, 28.8MB/s]\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "!kaggle datasets download -d achrafkhazri/yolo-weights-for-licence-plate-detector"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "7AdqnKpK9qHr",
                "outputId": "2ed1a3de-79e7-487e-ed32-bf7952ebf88d"
            },
            "execution_count": null,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Downloading yolo-weights-for-licence-plate-detector.zip to /content\n",
                        " 99% 216M/218M [00:08<00:00, 24.3MB/s]\n",
                        "100% 218M/218M [00:08<00:00, 25.6MB/s]\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Importer les Biblioth\u00e8ques**"
            ],
            "metadata": {
                "id": "lLimpIbUNQdq"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import os\n",
                "import cv2\n",
                "import time\n",
                "import random\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.utils import to_categorical\n",
                "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
                "import zipfile"
            ],
            "metadata": {
                "id": "Drqi3G-T9xQs"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Extraction des fichiers ZIP**"
            ],
            "metadata": {
                "id": "HJcfQr1rNWFa"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Sp\u00e9cifiez le chemin du fichier ZIP\n",
                "zip_file_path = '/content/car-number-plate-detection.zip'\n",
                "# Sp\u00e9cifiez le r\u00e9pertoire o\u00f9 vous souhaitez extraire les fichiers\n",
                "extract_directory = '/content/car-number-plate-detection'\n",
                "# Ouvrez le fichier ZIP\n",
                "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
                "    # Extrayez tous les contenus du fichier ZIP dans le r\u00e9pertoire sp\u00e9cifi\u00e9\n",
                "    zip_ref.extractall(extract_directory)\n",
                "print(\"Extraction termin\u00e9e.\")"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "tMfS3NgT-GgR",
                "outputId": "d6bb4b11-8b23-42f0-f3c6-265344b902b3"
            },
            "execution_count": null,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Unzipping complete.\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "# Sp\u00e9cifiez le chemin du fichier ZIP\n",
                "zip_file_path = '/content/yolo-weights-for-licence-plate-detector.zip'\n",
                "# Sp\u00e9cifiez le r\u00e9pertoire o\u00f9 vous souhaitez extraire les fichiers\n",
                "extract_directory = '/content/yolo-weights-for-licence-plate-detector'\n",
                "# Ouvrez le fichier ZIP\n",
                "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
                "    # Extrayez tous les contenus du fichier ZIP dans le r\u00e9pertoire sp\u00e9cifi\u00e9\n",
                "    zip_ref.extractall(extract_directory)\n",
                "print(\"Unzipping complete.\")"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "N3TaUQca-TCQ",
                "outputId": "6cceb07c-437f-4160-ead7-eddfec0a97d7"
            },
            "execution_count": null,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Unzipping complete.\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Parcours r\u00e9cursif d'un r\u00e9pertoire et r\u00e9cup\u00e9ration des chemins de fichiers**"
            ],
            "metadata": {
                "id": "O9DhovnmNx6_"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import os\n",
                "\n",
                "# Liste pour stocker les chemins des fichiers\n",
                "paths = []\n",
                "\n",
                "# Parcourir r\u00e9cursivement le r\u00e9pertoire '/content/car-number-plate-detection/Car_Number_Plate'\n",
                "# et r\u00e9cup\u00e9rer les chemins de tous les fichiers\n",
                "for dirname, _, filenames in os.walk('/content/car-number-plate-detection/Car_Number_Plate'):\n",
                "    for filename in filenames:\n",
                "        # Ajouter le chemin complet du fichier \u00e0 la liste des chemins\n",
                "        paths.append(os.path.join(dirname, filename))"
            ],
            "metadata": {
                "id": "PVaNjgCy9ygU"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "n=len(paths)\n",
                "N=6"
            ],
            "metadata": {
                "id": "RDwi9jAj_LiE"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "labels = open('/content/yolo-weights-for-licence-plate-detector/classes.names').read()"
            ],
            "metadata": {
                "id": "WIrJHlKI_N14"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Chemin vers les poids du mod\u00e8le YOLO\n",
                "weights_path = '/content/yolo-weights-for-licence-plate-detector/lapi.weights'\n",
                "# Chemin vers la configuration du mod\u00e8le YOLO\n",
                "configuration_path = '/content/yolo-weights-for-licence-plate-detector/darknet-yolov3.cfg'\n",
                "# Probabilit\u00e9 minimum pour filtrer les d\u00e9tections\n",
                "probability_minimum = 0.4\n",
                "# Seuil pour la suppression des d\u00e9tections faibles\n",
                "threshold = 0.3"
            ],
            "metadata": {
                "id": "Y4cxJMbQ_W5v"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Configuration du mod\u00e8le YOLO et param\u00e8tres de d\u00e9tection**"
            ],
            "metadata": {
                "id": "zmDFpslWN-e-"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Charger le mod\u00e8le Darknet \u00e0 partir de la configuration et des poids\n",
                "network = cv2.dnn.readNetFromDarknet(configuration_path, weights_path)\n",
                "\n",
                "# R\u00e9cup\u00e9rer les noms de toutes les couches du r\u00e9seau\n",
                "layers_names_all = network.getLayerNames()\n",
                "\n",
                "# R\u00e9cup\u00e9rer les indices des couches de sortie non connect\u00e9es\n",
                "layers_indices_output = network.getUnconnectedOutLayers()\n",
                "\n",
                "# V\u00e9rifier si layers_indices_output est un entier\n",
                "if isinstance(layers_indices_output, int):\n",
                "    # Convertir en liste\n",
                "    layers_indices_output = [layers_indices_output]\n",
                "\n",
                "# R\u00e9cup\u00e9rer les noms des couches de sortie \u00e0 partir des indices\n",
                "layers_names_output = [layers_names_all[i - 1] for i in layers_indices_output]"
            ],
            "metadata": {
                "id": "O5pWT0gY_ity"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Chargement et affichage de l'image**"
            ],
            "metadata": {
                "id": "jx5gC8Z4OZn2"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Lire l'image \u00e0 partir du chemin sp\u00e9cifi\u00e9\n",
                "image_input = cv2.imread(paths[N])\n",
                "\n",
                "# Redimensionner l'image en utilisant un facteur de r\u00e9duction de 0.2\n",
                "image_input = cv2.resize(image_input, dsize=None, fx=0.2, fy=0.2)\n",
                "\n",
                "# Afficher l'image en utilisant Matplotlib\n",
                "%matplotlib inline\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Configurer la taille de la figure\n",
                "plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
                "\n",
                "# Afficher l'image convertie en espace de couleur RGB\n",
                "plt.imshow(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))\n",
                "plt.show()\n"
            ],
            "metadata": {
                "id": "C159F9yS_8Fq"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Pr\u00e9paration de l'image pour la d\u00e9tection avec YOLO**"
            ],
            "metadata": {
                "id": "cYL_WuYTQrKR"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Convertir l'image en un blob d'entr\u00e9e pour le r\u00e9seau YOLO\n",
                "blob = cv2.dnn.blobFromImage(image_input, 1/255.0, (416,416), swapRB=True, crop=False)\n",
                "# R\u00e9organiser les dimensions du blob pour l'affichage\n",
                "blob_to_show = blob[0,:,:,:].transpose(1,2,0)\n",
                "# D\u00e9finir le blob en tant qu'entr\u00e9e pour le r\u00e9seau\n",
                "network.setInput(blob)\n",
                "# Obtenir les sorties du r\u00e9seau pour les couches de sortie sp\u00e9cifi\u00e9es\n",
                "output_from_network = network.forward(layers_names_output)\n",
                "# G\u00e9n\u00e9rer des couleurs al\u00e9atoires pour chaque \u00e9tiquette de classe\n",
                "np.random.seed(42)\n",
                "colours = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')"
            ],
            "metadata": {
                "id": "oaPV9A5AAAMv"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **D\u00e9tection d'objets avec YOLO et r\u00e9cup\u00e9ration des r\u00e9sultats**"
            ],
            "metadata": {
                "id": "aVJsT55uQ53S"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Listes pour stocker les bo\u00eetes englobantes, les confiances et les num\u00e9ros de classe\n",
                "bounding_boxes = []\n",
                "confidences = []\n",
                "class_numbers = []\n",
                "\n",
                "# R\u00e9cup\u00e9rer les dimensions de l'image\n",
                "h, w = image_input.shape[:2]\n",
                "\n",
                "# Parcourir les r\u00e9sultats de la sortie du r\u00e9seau\n",
                "for result in output_from_network:\n",
                "    # Parcourir les d\u00e9tections dans chaque r\u00e9sultat\n",
                "    for detection in result:\n",
                "        # R\u00e9cup\u00e9rer les scores de confiance pour chaque classe\n",
                "        scores = detection[5:]\n",
                "        # Trouver l'indice de classe avec la plus haute probabilit\u00e9\n",
                "        class_current = np.argmax(scores)\n",
                "        # R\u00e9cup\u00e9rer la confiance pour la classe actuelle\n",
                "        confidence_current = scores[class_current]\n",
                "        # V\u00e9rifier si la confiance d\u00e9passe le seuil minimum\n",
                "        if confidence_current > probability_minimum:\n",
                "            # R\u00e9cup\u00e9rer les coordonn\u00e9es de la bo\u00eete englobante et les ajuster \u00e0 la taille de l'image originale\n",
                "            box_current = detection[0:4] * np.array([w, h, w, h])\n",
                "            x_center, y_center, box_width, box_height = box_current.astype('int')\n",
                "            x_min = int(x_center - (box_width / 2))\n",
                "            y_min = int(y_center - (box_height / 2))\n",
                "            # Ajouter la bo\u00eete englobante, la confiance et le num\u00e9ro de classe aux listes correspondantes\n",
                "            bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n",
                "            confidences.append(float(confidence_current))\n",
                "            class_numbers.append(class_current)"
            ],
            "metadata": {
                "id": "Ka7mcusEAEEI"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Suppression des d\u00e9tections redondantes avec la suppression non maximale (NMS)**"
            ],
            "metadata": {
                "id": "WfTON2gLeYiI"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Supprimer les d\u00e9tections redondantes \u00e0 l'aide de la suppression non maximale (NMS)\n",
                "results = cv2.dnn.NMSBoxes(bounding_boxes, confidences, probability_minimum, threshold)\n",
                "\n",
                "# V\u00e9rifier s'il y a des r\u00e9sultats apr\u00e8s la suppression non maximale\n",
                "if len(results) > 0\n",
                "    # Parcourir les r\u00e9sultats aplatis\n",
                "    for i in results.flatten():\n",
                "        # R\u00e9cup\u00e9rer les coordonn\u00e9es et les dimensions de la bo\u00eete englobante\n",
                "        x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
                "        box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
                "        \n",
                "        # R\u00e9cup\u00e9rer la couleur de la bo\u00eete englobante pour la classe actuelle\n",
                "        colour_box_current = [int(j) for j in colours[class_numbers[i]]]\n",
                "        \n",
                "        # Dessiner la bo\u00eete englobante sur l'image d'entr\u00e9e\n",
                "        cv2.rectangle(image_input, (x_min, y_min), (x_min + box_width, y_min + box_height),\n",
                "                      colour_box_current, 5)\n",
                "        \n",
                "        # Ajouter le texte de la classe et de la confiance sur l'image d'entr\u00e9e\n",
                "        text_box_current = '{}: {:.4f}'.format(labels[int(class_numbers[i])], confidences[i])\n",
                "        cv2.putText(image_input, text_box_current, (x_min, y_min - 7), cv2.FONT_HERSHEY_SIMPLEX,\n",
                "                    1.5, colour_box_current, 5)\n"
            ],
            "metadata": {
                "id": "ZdlY_PJnAG2i"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "import matplotlib.pyplot as plt\n",
                "# Configurer la taille de la figure\n",
                "plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
                "# Afficher l'image convertie en espace de couleur RGB\n",
                "plt.imshow(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))\n",
                "plt.show()\n"
            ],
            "metadata": {
                "id": "Umv3UBjmAJHD"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}