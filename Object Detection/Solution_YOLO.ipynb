{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Reconnaissance des plaques d'immatriculation à l'aide de YoLo et DarkNet**"
      ],
      "metadata": {
        "id": "9opVMK6RKrHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://betterdatascience.com/detect-license-plates-with-yolo/images/1.jpg'>\n",
        "\n"
      ],
      "metadata": {
        "id": "cc0nQblznWeL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Darknet :**"
      ],
      "metadata": {
        "id": "5e-2KC_QofpI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://miro.medium.com/v2/resize:fit:512/0*GFsAY18k3A25IpRL'>"
      ],
      "metadata": {
        "id": "CmPifM2wot2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Darknet est un framework de réseau de neurones développé par Joseph Chet Redom. \n",
        "- Il s'agit essentiellement de nous fournir à tous un terrain de jeu pour construire nos propres modèles de réseaux de neurones. \n",
        "- Ce framework est écrit en « C » et « CUDA ». \n",
        "- Il est rapide et prend en charge les calculs CPU et GPU. \n",
        "-  Ce framework dépend des packages OpenCV et CUDA. Il prend en charge une large gamme de modèles tels que YOLO, RNN, etc. \n",
        "- Pour plus d'informations sur Darknet, vous pouvez visiter ce site Web https://pjreddie.com/darknet/ ."
      ],
      "metadata": {
        "id": "S1-DhzNIpR-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **YOLO _ V3 :**"
      ],
      "metadata": {
        "id": "0djjVef2pgGE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- YOLO signifie Y ou O nly L ook O nce. C'est l'un des algorithmes avancés actuels lorsque vous avez besoin d'une détection en temps réel (en millisecondes) de la classe et de la prédiction de la classe de cet objet détecté. \n",
        "- D'autre part, ce n'est pas l'algorithme le plus précis, mais c'est le meilleur des modèles de détection précis en temps réel.\n",
        "- Avant la version, nous avions les modèles yolo_v1 et yolo_v2. vous pouvez obtenir plus de détails dans leurs documents officiels publiés. yolo_v1 et yolo_v2 .\n",
        "\n",
        "- J'essaie d'expliquer un peu l'architecture v3. Il a un total de 106 couches. - Le meilleur avantage de ce modèle est qu'il fait des prédictions à trois échelles ( à la couche - 82 , 94 , 106 ). \n",
        "- Et en même temps, les images seront sous-échantillonnées leurs dimensions à 52 X 52 , 26X26 , 13X13 respectivement dans ces couches. Peu d'avantages sont\n",
        "\n",
        "1 . \n",
        "- Les caractéristiques sont détectées en multi-échelle (52 x 52 , 26 x 26 , 13x13 ).\n",
        "\n",
        "2. Réseau d'extracteurs de fonctionnalités plus puissant\n",
        "\n",
        "3. Fonction de perte optimisée\n",
        "\n",
        "- L'image suivante vous donne un aperçu plus détaillé de toutes les couches.\n",
        "\n"
      ],
      "metadata": {
        "id": "kYnbIS3Vpi-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://miro.medium.com/v2/resize:fit:1100/format:webp/0*3v10JDBF-1CApcQV.png'>"
      ],
      "metadata": {
        "id": "jBQ4DtKmpy3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- À haut niveau, les couches ci-dessus peuvent être divisées en deux catégories principales - Feature Extractor et Detector. \n",
        "- Lorsqu'une nouvelle image arrive dans le réseau, elle passe d'abord par l'extracteur de caractéristiques (les caractéristiques sortiront à trois étapes différentes à trois échelles différentes), puis ces caractéristiques sont introduites dans la branche du détecteur pour détecter les boîtes englobantes autour des objets détectés et enfin ces boîtes englobantes seront classées dans l'une des catégories."
      ],
      "metadata": {
        "id": "A1tZ3TpBqAVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://miro.medium.com/v2/resize:fit:1100/format:webp/0*RTdjlhEkAsFBMsU4.jpeg'>"
      ],
      "metadata": {
        "id": "2BM_4tj2qJoK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extracteur de fonctionnalités :**"
      ],
      "metadata": {
        "id": "GbA9wmwoqdV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- La fonctionnalité extracor dans YOLO V3 (également appelée Darknet -53) comporte elle-même 53 couches distinctes (sur un total de 106 couches). \n",
        "- Ces 53 couches de Darknet peuvent être expliquées avec le tableau suivant.\n",
        "<img src='https://miro.medium.com/v2/resize:fit:640/format:webp/0*lKqQiOgaDBjpjcZo.jpeg'>"
      ],
      "metadata": {
        "id": "275WqQuCqfTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- L'ensemble total du cadre peut être divisé en petits blocs indépendants qui sont connectés avec une couche de 2 convolutions. \n",
        "- Nous pouvons directement convertir cet extracteur de caractéristiques en classificateur en ajoutant trois couches distinctes (Avg-pool Connected et Soft-max). \n",
        "- Mais dans notre application de détection d'objets, nous utilisons ce Darknet-53 comme seul extracteur de fonctionnalités et est connecté à un bloc de couches de détection. \n",
        "- Nous n'inclurons donc pas les trois dernières couches dans notre modèle.\n",
        "\n",
        "- À partir de cet extracteur de caractéristiques, si nous insérons une image, cela donnera trois vecteurs de caractéristiques à différentes étapes du flux de réseau. \n",
        "- Ces trois fonctionnalités seront insérées séparément dans le bloc Détecteur."
      ],
      "metadata": {
        "id": "QqMVK-ApquqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importer la data depuis Kaggle**"
      ],
      "metadata": {
        "id": "T9QWeQ_-NIJI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WK8TRn_E6iy4"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AqUby-W8Spj",
        "outputId": "ce95a2e4-b54c-49df-e4ff-aae2d56a37d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "njeIZLvm8Vch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "er_lJoOa8a6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d elysian01/car-number-plate-detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLOipWVw8g3z",
        "outputId": "cc99bbcd-fe1c-4d59-ca77-5bd5dfec5a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading car-number-plate-detection.zip to /content\n",
            "100% 2.69G/2.69G [01:40<00:00, 33.2MB/s]\n",
            "100% 2.69G/2.69G [01:40<00:00, 28.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d achrafkhazri/yolo-weights-for-licence-plate-detector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AdqnKpK9qHr",
        "outputId": "2ed1a3de-79e7-487e-ed32-bf7952ebf88d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading yolo-weights-for-licence-plate-detector.zip to /content\n",
            " 99% 216M/218M [00:08<00:00, 24.3MB/s]\n",
            "100% 218M/218M [00:08<00:00, 25.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importer les Bibliothèques**"
      ],
      "metadata": {
        "id": "lLimpIbUNQdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "Drqi3G-T9xQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Extraction des fichiers ZIP**"
      ],
      "metadata": {
        "id": "HJcfQr1rNWFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Spécifiez le chemin du fichier ZIP\n",
        "zip_file_path = '/content/car-number-plate-detection.zip'\n",
        "# Spécifiez le répertoire où vous souhaitez extraire les fichiers\n",
        "extract_directory = '/content/car-number-plate-detection'\n",
        "# Ouvrez le fichier ZIP\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # Extrayez tous les contenus du fichier ZIP dans le répertoire spécifié\n",
        "    zip_ref.extractall(extract_directory)\n",
        "print(\"Extraction terminée.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMfS3NgT-GgR",
        "outputId": "d6bb4b11-8b23-42f0-f3c6-265344b902b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spécifiez le chemin du fichier ZIP\n",
        "zip_file_path = '/content/yolo-weights-for-licence-plate-detector.zip'\n",
        "# Spécifiez le répertoire où vous souhaitez extraire les fichiers\n",
        "extract_directory = '/content/yolo-weights-for-licence-plate-detector'\n",
        "# Ouvrez le fichier ZIP\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # Extrayez tous les contenus du fichier ZIP dans le répertoire spécifié\n",
        "    zip_ref.extractall(extract_directory)\n",
        "print(\"Unzipping complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3TaUQca-TCQ",
        "outputId": "6cceb07c-437f-4160-ead7-eddfec0a97d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Parcours récursif d'un répertoire et récupération des chemins de fichiers**"
      ],
      "metadata": {
        "id": "O9DhovnmNx6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Liste pour stocker les chemins des fichiers\n",
        "paths = []\n",
        "\n",
        "# Parcourir récursivement le répertoire '/content/car-number-plate-detection/Car_Number_Plate'\n",
        "# et récupérer les chemins de tous les fichiers\n",
        "for dirname, _, filenames in os.walk('/content/car-number-plate-detection/Car_Number_Plate'):\n",
        "    for filename in filenames:\n",
        "        # Ajouter le chemin complet du fichier à la liste des chemins\n",
        "        paths.append(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "PVaNjgCy9ygU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n=len(paths)\n",
        "N=6"
      ],
      "metadata": {
        "id": "RDwi9jAj_LiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = open('/content/yolo-weights-for-licence-plate-detector/classes.names').read()"
      ],
      "metadata": {
        "id": "WIrJHlKI_N14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chemin vers les poids du modèle YOLO\n",
        "weights_path = '/content/yolo-weights-for-licence-plate-detector/lapi.weights'\n",
        "# Chemin vers la configuration du modèle YOLO\n",
        "configuration_path = '/content/yolo-weights-for-licence-plate-detector/darknet-yolov3.cfg'\n",
        "# Probabilité minimum pour filtrer les détections\n",
        "probability_minimum = 0.4\n",
        "# Seuil pour la suppression des détections faibles\n",
        "threshold = 0.3"
      ],
      "metadata": {
        "id": "Y4cxJMbQ_W5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Configuration du modèle YOLO et paramètres de détection**"
      ],
      "metadata": {
        "id": "zmDFpslWN-e-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger le modèle Darknet à partir de la configuration et des poids\n",
        "network = cv2.dnn.readNetFromDarknet(configuration_path, weights_path)\n",
        "\n",
        "# Récupérer les noms de toutes les couches du réseau\n",
        "layers_names_all = network.getLayerNames()\n",
        "\n",
        "# Récupérer les indices des couches de sortie non connectées\n",
        "layers_indices_output = network.getUnconnectedOutLayers()\n",
        "\n",
        "# Vérifier si layers_indices_output est un entier\n",
        "if isinstance(layers_indices_output, int):\n",
        "    # Convertir en liste\n",
        "    layers_indices_output = [layers_indices_output]\n",
        "\n",
        "# Récupérer les noms des couches de sortie à partir des indices\n",
        "layers_names_output = [layers_names_all[i - 1] for i in layers_indices_output]"
      ],
      "metadata": {
        "id": "O5pWT0gY_ity"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Chargement et affichage de l'image**"
      ],
      "metadata": {
        "id": "jx5gC8Z4OZn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lire l'image à partir du chemin spécifié\n",
        "image_input = cv2.imread(paths[N])\n",
        "\n",
        "# Redimensionner l'image en utilisant un facteur de réduction de 0.2\n",
        "image_input = cv2.resize(image_input, dsize=None, fx=0.2, fy=0.2)\n",
        "\n",
        "# Afficher l'image en utilisant Matplotlib\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Configurer la taille de la figure\n",
        "plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
        "\n",
        "# Afficher l'image convertie en espace de couleur RGB\n",
        "plt.imshow(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "C159F9yS_8Fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Préparation de l'image pour la détection avec YOLO**"
      ],
      "metadata": {
        "id": "cYL_WuYTQrKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir l'image en un blob d'entrée pour le réseau YOLO\n",
        "blob = cv2.dnn.blobFromImage(image_input, 1/255.0, (416,416), swapRB=True, crop=False)\n",
        "# Réorganiser les dimensions du blob pour l'affichage\n",
        "blob_to_show = blob[0,:,:,:].transpose(1,2,0)\n",
        "# Définir le blob en tant qu'entrée pour le réseau\n",
        "network.setInput(blob)\n",
        "# Obtenir les sorties du réseau pour les couches de sortie spécifiées\n",
        "output_from_network = network.forward(layers_names_output)\n",
        "# Générer des couleurs aléatoires pour chaque étiquette de classe\n",
        "np.random.seed(42)\n",
        "colours = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')"
      ],
      "metadata": {
        "id": "oaPV9A5AAAMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Détection d'objets avec YOLO et récupération des résultats**"
      ],
      "metadata": {
        "id": "aVJsT55uQ53S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Listes pour stocker les boîtes englobantes, les confiances et les numéros de classe\n",
        "bounding_boxes = []\n",
        "confidences = []\n",
        "class_numbers = []\n",
        "\n",
        "# Récupérer les dimensions de l'image\n",
        "h, w = image_input.shape[:2]\n",
        "\n",
        "# Parcourir les résultats de la sortie du réseau\n",
        "for result in output_from_network:\n",
        "    # Parcourir les détections dans chaque résultat\n",
        "    for detection in result:\n",
        "        # Récupérer les scores de confiance pour chaque classe\n",
        "        scores = detection[5:]\n",
        "        # Trouver l'indice de classe avec la plus haute probabilité\n",
        "        class_current = np.argmax(scores)\n",
        "        # Récupérer la confiance pour la classe actuelle\n",
        "        confidence_current = scores[class_current]\n",
        "        # Vérifier si la confiance dépasse le seuil minimum\n",
        "        if confidence_current > probability_minimum:\n",
        "            # Récupérer les coordonnées de la boîte englobante et les ajuster à la taille de l'image originale\n",
        "            box_current = detection[0:4] * np.array([w, h, w, h])\n",
        "            x_center, y_center, box_width, box_height = box_current.astype('int')\n",
        "            x_min = int(x_center - (box_width / 2))\n",
        "            y_min = int(y_center - (box_height / 2))\n",
        "            # Ajouter la boîte englobante, la confiance et le numéro de classe aux listes correspondantes\n",
        "            bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n",
        "            confidences.append(float(confidence_current))\n",
        "            class_numbers.append(class_current)"
      ],
      "metadata": {
        "id": "Ka7mcusEAEEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Suppression des détections redondantes avec la suppression non maximale (NMS)**"
      ],
      "metadata": {
        "id": "WfTON2gLeYiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Supprimer les détections redondantes à l'aide de la suppression non maximale (NMS)\n",
        "results = cv2.dnn.NMSBoxes(bounding_boxes, confidences, probability_minimum, threshold)\n",
        "\n",
        "# Vérifier s'il y a des résultats après la suppression non maximale\n",
        "if len(results) > 0\n",
        "    # Parcourir les résultats aplatis\n",
        "    for i in results.flatten():\n",
        "        # Récupérer les coordonnées et les dimensions de la boîte englobante\n",
        "        x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
        "        box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
        "        \n",
        "        # Récupérer la couleur de la boîte englobante pour la classe actuelle\n",
        "        colour_box_current = [int(j) for j in colours[class_numbers[i]]]\n",
        "        \n",
        "        # Dessiner la boîte englobante sur l'image d'entrée\n",
        "        cv2.rectangle(image_input, (x_min, y_min), (x_min + box_width, y_min + box_height),\n",
        "                      colour_box_current, 5)\n",
        "        \n",
        "        # Ajouter le texte de la classe et de la confiance sur l'image d'entrée\n",
        "        text_box_current = '{}: {:.4f}'.format(labels[int(class_numbers[i])], confidences[i])\n",
        "        cv2.putText(image_input, text_box_current, (x_min, y_min - 7), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    1.5, colour_box_current, 5)\n"
      ],
      "metadata": {
        "id": "ZdlY_PJnAG2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Configurer la taille de la figure\n",
        "plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
        "# Afficher l'image convertie en espace de couleur RGB\n",
        "plt.imshow(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Umv3UBjmAJHD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}